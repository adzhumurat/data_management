{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning в продакшне\n",
    "\n",
    "Поговорим, от том, как выводить модели в продакшн. Вы уже знакомы с понятием \"жизненный цикл ML проекта\" - сегодня мы увидим, как этот цикл выглядит в реальной жизни и попробуем вывести в продакшн модель классификации с помощью технологии виртуализации Docker (можно и без docker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом уроке мы поговорим о том, как обосновать перед бизнесом необходимость внедрения новой ML-системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оффлайн эксперимент. Proof concept\n",
    "\n",
    "В рамках курса вы\n",
    "* узнали про огромное количество моделей: классификация, регрессия\n",
    "* научились оценивать качество моделей \n",
    "* можете готовить данные для алгоритмов, включая генерацию фичей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, бизнесу не интересны задачи классификации или регрессии - бизнесу интересно зарабатывать деньги. Чтобы заработать деньги с помощью ML нужно найти конкретную бизнес-проблему, поиском проблем в бизнесе должен заниматься владелец бизнеса (в методологии Agile его зовут Product Owner) и понять, как эту бизнес-проблему можно решить. После такого  начального этапа выявления проблемы бизнес-хотелка отдаётся ML-специалисту, который должен создать инженерное решение для проблемы и интергрировать его в продакшн - после выкатывания прототипа \"в прод\" бизнес начинает зарабатывать миллионы и все счастливы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже я приведу полный путь от бизнес-идеи до прототипа - такой путь проходит любой проект ML, а называют такой пайплайн Proof of concept:\n",
    "\n",
    "1. Перейти от общих слов продукт оунера к конкретным бизнес-требованиям. Желательно, чтобы DS проводил её сам (возможно привлечь бизнес-аналитика).\n",
    "1. Описать дизайн (схему) эксперимента. Нужно понять, как повлиять на бизнес-метрики из первого пункта. На этом этапе нужно понять, какая информация доступна на входе, что ожидается на выходе и к какой задаче ML это можно свести  какие метрики покажут успешность задачи\n",
    "1. Разобраться с данными: где храняться достаточно ли их для проверки гипотезы. Неплохо бы сразу осознать, будут ли данные в продакшене отличаться от того, что доступно в трейне.\n",
    "1. Наинженерить фич и построить модель\n",
    "1. Оценить качество модели, посчитать технические и бизнесовые метрики (см. третий урок)\n",
    "1. Оценить ROI (Return on Investment) — ради этого всё и затевается.\n",
    "\n",
    "Фишка этих шагов в том, что ошибка на любом шаге сильно ухудшает весь проект - например, плохая постановка бизнес-требований приведёт к провальному эксперименту. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчёт ROI - самый важный, финальный этап. Без расчёта эффективности бизнес-заказчик не даст вам добра на выкатывание в продакшн. \n",
    "\n",
    "ROI  — это показатель доходности проекта, равный отношению доходов к затраченным инвестициям. ROI < 100% означает, что проект не окупится.\n",
    "\n",
    "`ROI` = (`LTP`)/(`CL` + `LTL`)\n",
    "\n",
    "1. LTP(Lifetime Profit)  - сколько доходов принесёт проект, пока его не свернут. Вычисляется как *операционные доходы* $\\times$ *срок жизни*\n",
    "1. CL (Capital Loss) - затраты на старт проекта\n",
    "1. LTL(Lifetime Loss)  - сколько расходов принесёт проект, пока его не свернут. Вычисляется как *операционные расходы проекта* $\\times$ *срок жизни проекта*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В капитальные затраты входит закупка железа и лицензий, разработку системы и ее внедрение. Операционные расходы - это то, что тратится на поддержание сервиса: зарплата программистов, devops-инженеров, аренда серверов.\n",
    "\n",
    "Из-за \"мгновенных\" капитальных расходов на старте проекта ROI будет зависеть от времени, на котором мы оцениваем доходность. Обычно для расчета ROI используется или год - нужно понять, окупится проект за год или нет.\n",
    "\n",
    "\n",
    "На далеком горизонте планирования можно окупить любую систему, поэтому важно понять величину *Lifetime* - сколько проработает система "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы узнали, что такое Proof of concept: какие действия нужно произвести чтобы понять, что модель будет полезна и принесёт выгоду. В следующем уроке мы поговорим о метриках сервиса - как понять, что модель действительно работает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики моделей ML\n",
    "\n",
    "Метрики ML-сервисов (как и любых других продакшн-систем) можено разделить на три основных группы\n",
    "\n",
    "* оффлайн-метрики модели\n",
    "* технические метрики сервиса\n",
    "* продуктовые (бизнес) метрики\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оффлайн метрики\n",
    "\n",
    "Оффлайн-метрики показывают, насколько хорошо алгоритм \"выучил\" исторические данные. С этими метриками вы сталкивались в течение всего курса:\n",
    "\n",
    "* RMSE\n",
    "* MAE\n",
    "* precision\n",
    "* recall\n",
    "* accuracy\n",
    "* MAP\n",
    "* $\\ldots$\n",
    "\n",
    "Эти метрики не могут сказать, что модель будет достаточно хороша для бизнеса, но такая модель, как минимум, будет \"не совсем плоха\" чтобы отказываться от её выкатывания в прод. То есть выкатывают модель с хорошими оффлайн метриками и надеются, что она улучшит онлайн-метрики (см. дальше)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В реальной жизни обучение модели запускается регулярно, поэтому оффлайн-метрики нуждаются в мониторинге.\n",
    "\n",
    "Пример из боевой системы обучения моделей: если ROC-AUC падает ниже 0.8, то модель в продакшн не выкатывается, а разработчику приходит уведомление в slack: дружище, с твоей моделью что-то не так, посмотри что случилось:\n",
    "\n",
    "```shell\n",
    "12:11:52,344 | INFO     | hydramatrices_data.py    :65   | Данные из HDFS загружены\n",
    "12:12:10,651 | INFO     | learn2rank_model.py      :168  | Разбили данные на train и test\n",
    "12:13:15,113 | INFO     | learn2rank_model.py      :248  | Кол-во объектов в train 1643676\n",
    "12:14:24,329 | INFO     | learn2rank_model.py      :265  | Новая модель Learning to Rank c2c готова\n",
    "12:14:49,295 | INFO     | learn2rank_model.py      :268  | Train Area under ROC = 0.8517\n",
    "12:15:11,057 | INFO     | learn2rank_model.py      :272  | Test Area under ROC = 0.8516\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Технические метрики\n",
    "\n",
    "Технические метрики сервиса - это некоторые показатели \"здоровья\", железа, которые никак не связаны с логикой\n",
    "\n",
    "* `RPS` (response per second) - сколько запросов в секунду прилетает на сервис\n",
    "* `response time` - время ответа сервиса\n",
    "* `CPU idle` - \"бездействие системы\", чем больше тем лучше. Если падает idle - значит, сильно загружен процессор\n",
    "* `available memory` - сколько памяти доступно на серверах\n",
    "* `500 errors` - количество 500-х ошибок на сервисе\n",
    "\n",
    "Дэшборды с техническими метриками могут выглядеть как-то так:\n",
    "\n",
    "![tech_metrics](img/tech_metrics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сбора и визуализации технических метрик используются следующие инструменты, которые должен знать каждый ML специалист:\n",
    "\n",
    "* statsd - хранение метрик\n",
    "* Grafana - визуализиция графиков\n",
    "* Zabbix - визуализация и отправка уведомлений (например, в slack)\n",
    "* Sentry - для анализа 500-х ошибок\n",
    "* Kibana - логи сервиса\n",
    "\n",
    "Прежде чем катить модель в прод нужно ознакомиться с каждым из этих инструментов и интегрировать с ними свою модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Продуктовые метрики\n",
    "\n",
    "Продуктовые метрики это то, что в первую очередь интересует бизнес. Когда выкатываете новую модель - она должна делать бизнесу лучше, а делать ML ради ML точно не стоит\n",
    "\n",
    "Какие метрики можно улучшить с помощью ML\n",
    "\n",
    "* средний чек\n",
    "* retention - возвращаемость клиентов на сервис\n",
    "* churn - отток клиентов с сервиса\n",
    "* bounce - % пользователей, которые зашли на сервис, но ничего не сделали  (показатель отказов)\n",
    "* конверсия в покупку\n",
    "\n",
    "Проверять, что ваша модель улучшает метрики следует с помощью АБ-теста\n",
    "\n",
    "![ab_testing](img/ab_testing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы узнали, как следить за моделями в продакшн. Вы познакомились с понятием \"технические метрики сервиса\" и теперь знаете, как сделать из \"чёрного ящика\" вашей модели прозрачный и управляемый сервис \n",
    "\n",
    "В следующем уроке мы перейдём к самому интересному - поговорим, как разворачивать модели на боевых серверах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Деплой модели: Docker\n",
    "\n",
    "Этапы разработки прод-сервиса:\n",
    "* разведочный анализ данных\n",
    "* прототип модели в Jupyter\n",
    "* продакшн-сервис\n",
    "\n",
    "Как же перейти от любимого Jupyter ноутбука к продакшин сервису? Современные архитектуры web-проектов предполагают т.н. микросервисную архитектуру, когда для решения конкретной бизнес задачи поднимается маленький веб-сервис, который умеет принимать http-запросы и делать predict, возвращая предсказания в виде json-объекта.\n",
    "\n",
    "JSON - это стадартный формат для общения микросервисов друг с другом, о нём говорили в самом начале курса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![microservices-logical.png](img/microservices-logical.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как упаковать модель в микросервис? Для этого питоновский код нужно обернуть в http-сервер, который будет \"сёрвить\" (обслуживать) http-запросы. Вариантов http-сервера очень много\n",
    "\n",
    "* [Flask](https://palletsprojects.com/p/flask/)\n",
    "* [aiohttp](https://aiohttp.readthedocs.io/en/stable/)\n",
    "* [http.server](https://docs.python.org/3/library/http.server.html)\n",
    "\n",
    "Такой сервис обычно имеет url, на который можно отправлять запросы в заранее определённом формате, например `https://you.service/classify?uid=999` и возвращать ответ в JSON `{'uid': 999, 'class': 1}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При чём тут **Docker**? Докер - это система виртуализации, которая позволяет унифицировать среду разработки и среду выполнения приложения: вы пишете код, который исполняется в виртуальной машине, тестируете его - а потом на боевые сервера отправляется та же самая виртуальная машина."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что вам не нужно волноваться о том, как будет жить питоновский код в продакшне - потому что будет исполняться в той же среде, в которой вы его разрабатывали (и тестировали). Докер является де-факто стандартом в мире современных архитектур для деплоя (т.е. вывода в продакшн-среду) моделей ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простой докер-контейнер\n",
    "\n",
    "Вы уже пользовались докером для разворачивания Postgres базы данных, но не писали своих докерфайлов. Давайте исправим этот факт и напишем простой докер-сервис! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм упаковки сервиса в докер следующий\n",
    "\n",
    "1. Выбрать базовый образ. Я выбрал образ, в который включены такие библиотеки как sklearn, numpy и pandas https://hub.docker.com/r/morpheo/sklearn-base/\n",
    "1. Чтобы докер делал что-то полезное, нужно запустить внутри него программу. Программы внутри контейнера принято запускать через файл `docker-entrypoint.sh`. Для примера я создал файл [simple-entrypoint.sh](docker_example/simple-entrypoint.sh), внутри которого всего одна инструкция `echo \"Hello, MAI!\"`\n",
    "1. Чтобы собрать контейнер, нужно описать его структуру в Dockerfile. Загляните в файл [Dockerfile_simple](docker_example/Dockerfile), где описана структура нашего контейнера\n",
    "\n",
    "```dockerfile\n",
    "FROM morpheo/sklearn-base\n",
    "\n",
    "COPY simple_entrypoint.sh /usr/local/bin/docker-entrypoint.sh\n",
    "RUN chmod +x /usr/local/bin/docker-entrypoint.sh\n",
    "\n",
    "ENTRYPOINT [\"docker-entrypoint.sh\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находясь в директории `docker_example` надо запустить сборку контейнера командой\n",
    "```shell\n",
    "docker build . -f Dockerfile_simple -t mai:simple\n",
    "```\n",
    "\n",
    "После окончания процесса сборки запустить контейнер с помощью инструкции `docker run`:\n",
    "```shell\n",
    "docker run -it --rm  mai:simple\n",
    "```\n",
    "\n",
    "В результате должны увидеть в консоли `Hello, MAI!`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы создали простой контейнер (для понимания), который только и умеет что выводить на печать простую фразу. В следующем уроке мы упакуем в докер пайплайн для тренировки и развёртывания модели машинного обучения в виде http-сервиса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Упаковка модели в Docker: этап research\n",
    "\n",
    "Перед тем, как погружаться в мир докера, создадии пайплайн обучения на python.\n",
    "\n",
    "Начнём с загрузки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_diff</th>\n",
       "      <th>sms_diff</th>\n",
       "      <th>traffic_diff</th>\n",
       "      <th>customes_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.666421</td>\n",
       "      <td>0.444911</td>\n",
       "      <td>-0.273538</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.889273</td>\n",
       "      <td>-0.537896</td>\n",
       "      <td>-1.959469</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.841503</td>\n",
       "      <td>0.846665</td>\n",
       "      <td>0.727606</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   call_diff  sms_diff  traffic_diff  customes_class\n",
       "0  -0.666421  0.444911     -0.273538             0.0\n",
       "1  -0.889273 -0.537896     -1.959469             2.0\n",
       "2  -0.841503  0.846665      0.727606             0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_source = pd.read_csv('data/client_segmentation.csv')\n",
    "X = df_source[['call_diff','sms_diff','traffic_diff']].values\n",
    "y = df_source.customes_class.values\n",
    "\n",
    "df_source.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это датасет, в котором три фичи `call_diff`, `sms_diff` и `traffic_diff` которые отражают относительное изменение в объёме звонков, смс и интернет-трафика соответственно по абонентам в базе телеком-оператора и несколько классов клиентов:\n",
    "\n",
    "* класс `0` - пользователь платит много\n",
    "* класс `1` - пользователь платит мало\n",
    "* класс `2` - пользователь ушёл в отток (не платит ничего)\n",
    "\n",
    "От нас требуется обучить модель классификации на три класса. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для визуализации данных выполним понижение размерности с помощью *t-sne*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "\n",
    "x_tsne = TSNE(n_components=2).fit_transform(X)\n",
    "colors = ['bo', 'gx', 'ro']; num_labels = len(colors)\n",
    "# И нарисуем получившиеся точки в нашем новом пространстве\n",
    "for name, label, color in [('class_%d' % i, i, colors[i]) for i in range(num_labels)]:\n",
    "    plt.plot(x_tsne[y == label, 0], x_tsne[y == label, 1], color, label=\"class %d\" % label)\n",
    "plt.legend(loc=0); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бизнесу требуется построить классификатор клиентов - давате обучим простенький классификатор, основанный на решающем дереве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У объекта под номером 68 класс 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# выбираем рандомный объект\n",
    "\n",
    "num_objects = X.shape[0]\n",
    "random_id = np.random.randint(num_objects)\n",
    "\n",
    "# преобразуем фичи, чтобы подошли на вход модели и делаем предсказания\n",
    "test_object = X[random_id,:].reshape(1, -1)\n",
    "pred = clf.predict(test_object)\n",
    "print(f\"У объекта под номером {random_id} класс {pred[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гототово, у нас есть модель, которая что-то обучает и что-то предсказывает. Можем сериализовать её для дальнейшего использования c помощью `pickle`. А теперь попробуем обернуть в докер наш пайплан обучения модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовый контейнер для сервиса я взял отсюда: https://hub.docker.com/r/frolvlad/alpine-python-machinelearning/ . Он включает python 3.5 и библиотеки numpy и sklearn - больше нам для обучения модели ниего не надо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск сборки\n",
    "```shell\n",
    " docker build . -f Dockerfile -t mai:advanced\n",
    "```\n",
    "Запуск обучения модели - см. файл `train.py`\n",
    "```shell\n",
    "docker run -it --rm  -v $(pwd)/data:/www/classifier/data mai:advanced train_model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вся полезная информация отправляется в файл с логами\n",
    "```shell\n",
    "tail -n1 data/service.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример логов модели\n",
    "```shell\n",
    "2020-04-24 06:55:54,070 | INFO     | service.py               :70   | Загружаем обученную модель\n",
    "2020-04-24 06:55:54,071 | INFO     | service.py               :73   | Модель загружена: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=42, splitter='best')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск микросервиса - см. в файле `service.py`\n",
    "```shell\n",
    "docker run -it --rm  -v $(pwd)/data:/www/classifier/data -p 5000:5000 -d mai:advanced start_service\n",
    "```\n",
    "\n",
    "Увидеть запущенный контейнер можно через Docker ps\n",
    "```shell\n",
    "docker ps\n",
    "```\n",
    "\n",
    "Результат команды\n",
    "```shell\n",
    "CONTAINER ID        IMAGE                     COMMAND                  CREATED             STATUS              PORTS                    NAMES\n",
    "c9ba7303712c        mai:advanced   \"docker-entrypoint.s…\"   14 hours ago        Up 14 hours         0.0.0.0:5000->5000/tcp   infallible_easley\n",
    "```\n",
    "\n",
    "Чтобы проверить, что сервис \"жив\" и способен принимать запросы откройте в браузере спициальную страничку `http://0.0.0.0:5000/ping/` - это т.н. *healh check* нашего сервиса. В браузере должно появится\n",
    "```json\n",
    "{\"message\": \"pong\"}\n",
    "```\n",
    "\n",
    "Хороший туториал по [упаковке моделей в контейнеры](https://towardsdatascience.com/deploying-machine-learning-models-with-docker-5d22a4dacb5). Там можно почитать, как скейлить нагрузку помощью nginx+gunikorn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем датасете три фичи - нам нужно передать их в наш микросервис. Передавать фичи можно через GET-запросы, например, так:\n",
    "```url\n",
    "http://0.0.0.0:5000/classifier/?x1=1&x2=-2.2&x3=1.05\n",
    "```\n",
    "\n",
    "Дальше нам нужно перехватить их на стороне сервиса, обработать фичи, загрузив в классификатор и выдать ответ:\n",
    "```json\n",
    "{\"x1\": 1.0, \"x2\": -2.2, \"x3\": 1.05, \"predicted_class\": 0}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После окончания работ контейнер можно остановить\n",
    "```shell\n",
    "docker stop c9ba7303712c\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы упаковали модель в докер и можем использовать модель как микросервис - отправлять запросы и получать предсказания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обобщим все наши знания о микросервисах в одной картинке\n",
    "\n",
    "* у микросервиса должен быть определён формат ответа в виде JSON схемы\n",
    "* Consul - это сервис, который автоматически дёргает *health check* и рестартует контейнер, если он перестал отвечать\n",
    "* блок `logs` - это Elastic+Logstash+Kibana, связка используется для хранения логов\n",
    "* технические метрики отправляются в хранилище Prometheus и визуализируются  в Grafana. Нотификации в случае нештатных ситуаций отправляются в Slack\n",
    "* инциденты в виде 500-х ошибок отправляются в Sentry для дальнейшего анализа\n",
    "\n",
    "![microservice.png](img/microservice.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: применяем PCA-трансформацию\n",
    "\n",
    "[Домашка тут](https://github.com/aleksandr-dzhumurat/data_management/blob/master/jupyter_notebooks/VI_machine_learning_production_hw.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML в проде: рекомендательные системы\n",
    "\n",
    "Рекомендательные системы - это обобщённое название для сервисов, которые в ответ на запрос формируют из огромной коллекции доступных сущностей (мы будем называть их \"документами\", англ. item но в реальной жизни это фильмы в онлайн-кинотеатре или товары в интернет-магазине, а саму такую коллекцию документов для краткости будем называть каталогом) некоторый шорт-лист, который будет наиболее подходящим для данного запроса (такие документы называются \"релевантными\"). Рекомендательные системы используют для решения своих задач другие алгоритмы ML.\n",
    "О том, как на основе уже изученных ML-алгоритмов научиться решать задачу поиска релевантных объектов мы поговорим в этом  уроке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендательные системы: цели и задачи\n",
    "\n",
    "Основная задача рекомендательной системы - нарезать шорт-лист из каталога, который будет максимально подходить к контексту, в котором запрашиваются рекомендации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под \"контекстом\" мы понимаем различные параметры мира, который окружает рекомендательную систему:\n",
    "\n",
    "* с какими документами из каталога уже взаимодействовал пользователь\n",
    "* какова \"сила\" взаимодействия - лайк или дизлайк? Если оценка - то какая? Если просмотр фильма - то как долго смотрел?\n",
    "* в какой стране находится пользователь - в Казахстане смотрят фильм \"Рэкетир\" а в России \"Бумер\".\n",
    "* утро или вечер в момент посмотрения рекомендаций\n",
    "* что по соцдему - какого пола и возраста пользователь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача рекомендаций представляет собой задачу *ранжирования* - мы пытаемся расставить контент в таком порядке, чтобы в начале списка был самый релевантный контент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот, например, как выглядит главная страница ivi - по сути, это персонализованная нарезка из доступного каталога контента\n",
    "\n",
    "![ivi_main](img/ivi_catalog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Различают два вида рекомендаций:\n",
    "\n",
    "* *content to user*  строятся на основе фидбэка, полученного от пользователя (например, лайкнутые фильмы)\n",
    "* *content to content* строятся на основе свойств контента найти максимально похожие на него элементы (например, блок \"С этим часто покупают\" на Ozon)\n",
    "\n",
    "Рекомендательная система решает задачу персонализации сервиса - это значит, что каждый пользователь  видит свой вариант сервиса - можно сказать, что у вас появляется столько вариантов наполнения страниц вашего сайта, сколько у вас пользователей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендательные системы нужны в ситуации, когда пользователь не может сделать выбор из огромного количества возможных вариантов каталога (например, каталога интернет-магазина) и ему нужно как-то помочь, ограничив выбор узким кругом объектов, которые больше всего подходят к текущему контексту - такие объекты и называются *релевантными*. Избавив пользователя от необходимости просматривать огромное число неподходящих объектов, рекомендательная система позволяет быстрее сконвертировать пользовательскую сессию в \"целевое действие\" - просмотр фильма или покупку гаджета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует два основных метода для поиска релелевантных объектов\n",
    "\n",
    "* collaborative filtering\n",
    "* content filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели *коллаборативной фильтрации* используют интуитивное предположение о том, что если у двух пользователей сильно пересекаются два множества контента (с которым они взаимодействовали) то у этих двух пользователей схожие вкусы - на основе этого можно делать рекомендации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, у нас есть информация о пользователях `X, Y, Z` и фильмах `A, B, C, D, E`. В таблице символ \"+\" означает, что пользователь $i$ смотрел фильм $j$:\n",
    "\n",
    "| - | A | B | C | D | E |\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "| X  | +  | -  | +  | +  | -  |\n",
    "| Y  | -  | +  | -  | -  | +  |\n",
    "| Z  | +  | +  | -  | +  | -  |\n",
    "\n",
    "Как видно, пользователи `X, Z` очень похожи друг на друга, т.к. им обоим нравится фильмы \"А\" и \"D\".\n",
    "\n",
    "В то же время пользователь `Y` не похож на них, он смотрит другие фильмы. Из картинки видно, что если бы нам нужно было бы построить персональные рекомендации для пользователя `X`, то мы бы порекомендовали  ему фильм `B` - такой фильм смотрел пользователь Z и значит, этот фильм понравится пользователю X, потому что данные говорят о том, чт вкусы этих двух пользователей похожи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Content-based* фильтрация подбирает похожие элементы на основе свойств контента. Например, в случае фильма его свойства - это актёр, режиссёр, жанр, место действия и т.д. Например, если у нас естьфильм со Стэтхемом, то максимально похожим будет, скорее всего, другой фильм со Стэтхэмом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выделяют *гибридные* рекомендательные системы - в этом случае рекомендации из нескольких моделей (например, `content based` + `collaborative filterig`) используются для формирования итогового ранжирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колаборативные модели обучаются на триплетах (тройках) `(user, item, feedback)`, где для каждой пары `(user, item)` фидбэк может быть двух видов:\n",
    "\n",
    "* explicit (явный)\n",
    "* implicit (неявный)\n",
    "\n",
    "*Явный фидбэк* - это любое явное выражение пользователем своего отношения к контенту: лайк, оценка и т.д. *Неявный фидбэк* - это длительность просмотра фильма, количество заходов на карточку товара, время чтения статьи и т.д.: интуитивно понятно, что если пользователь смотрит фильм долго - то такой фильм, скорее всего, ему нравится, но явного сигнала (например, в виде лайка) мы не получаем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача построения рекомендации решается с помощью классических алгоритмов машинного обучения:\n",
    "\n",
    "* метод ближайших соседей (knn)\n",
    "* матричная факторизация\n",
    "* логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендатель отдаёт отранжированный список объектов. На этот список обычно накладываются разнообразные бизнес-правила, позволяющие оптимизировать метрики, важные для бизнеса: например, искуственное повышение новинок в выдаче.\n",
    "\n",
    "Грамотно построенная рекомендательная система позволяет нарастить продуктовые метрики. Например, в онлайн-кинотеатре:\n",
    "\n",
    "* растёт конверсия в просмотр т.к. пользователь получает на главной странице самый подходящий контент\n",
    "* увеличивается длительности смотрения на пользователя, удачно рекомендованный сериал генерирует десятки часов смотрения\n",
    "* уменьшается отток с сервиса - пользователь за одну сессию может выбрать несколько фильмов, которые будет смотреть несколько заходов подряд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN рекомендации\n",
    "\n",
    "Мы попробуем построить простейшую модель коллаборативной фильтрации, пользуясь только информацией о просмотрах контента в онлайн-кинотеатре ivi.\n",
    "\n",
    "Загрузим исходные данные - там примерно полмиллиона просмотров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество просмотров 489565\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>view_duration</th>\n",
       "      <th>view_ts</th>\n",
       "      <th>dt</th>\n",
       "      <th>platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4649</td>\n",
       "      <td>52867</td>\n",
       "      <td>735</td>\n",
       "      <td>2019-03-18 20:40:57+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>48800</td>\n",
       "      <td>361</td>\n",
       "      <td>2019-03-18 11:48:27+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5380</td>\n",
       "      <td>47146</td>\n",
       "      <td>268</td>\n",
       "      <td>2019-02-17 13:06:33+03:00</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
       "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
       "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
       "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
       "\n",
       "  platform  \n",
       "0       LG  \n",
       "1       LG  \n",
       "2       LG  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "content_views = pd.read_csv(\n",
    "    'recsys_data/content_views.zip', delimiter=',', header=0, compression='zip',\n",
    "    names = ['user_id', 'content_id', 'view_duration', 'view_ts', 'dt', 'platform'],\n",
    "    dtype = {'user_id': np.uint32, 'content_id': np.uint16, 'view_duration': np.uint16},\n",
    "    parse_dates = [3, 4]\n",
    ")\n",
    "\n",
    "\n",
    "print('Количество просмотров %s' % content_views.user_id.count())\n",
    "\n",
    "content_views.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим дополнительную информацию о контенте: жанры, дату появления на сервисе, рейтинг кинопоиска и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество доступного контента 126182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>release_date</th>\n",
       "      <th>kinopoisk_rating</th>\n",
       "      <th>compilation_id</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1974</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-15</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2148</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-21</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2184</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-22</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_id  origin_country release_date  kinopoisk_rating  compilation_id  \\\n",
       "0        1974            87.0   2009-12-15              7.27             153   \n",
       "1        2148            87.0   2009-12-21              7.27             153   \n",
       "2        2184            87.0   2009-12-22              7.27             153   \n",
       "\n",
       "       genre  \n",
       "0  Для детей  \n",
       "1  Для детей  \n",
       "2  Для детей  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_description = pd.read_csv(\n",
    "    'recsys_data/content_description.zip', delimiter=',', header=0, compression='zip',\n",
    "    names = ['content_id', 'origin_country', 'release_date', 'kinopoisk_rating', 'compilation_id', 'genre'],\n",
    "    dtype = {'content_id': np.uint16},\n",
    "    parse_dates = [2]\n",
    ")\n",
    "\n",
    "print('Количество доступного контента %s' % content_description.content_id.count())\n",
    "\n",
    "content_description.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем разреженную матрицу user-item такую, что\n",
    "\n",
    "* количество строк матрицы совпадает с числом пользователей\n",
    "* количество столбцов матрицы совпадает с количеством контента\n",
    "* на пересечении столбца $i$ и строки $j$ стоит единица, если пользователь $i$ смотрел контент $j$, иначе - ноль\n",
    "\n",
    "Для начала перейдём от индекса контента и индекса пользователя к индексам в разреженной матрице - воспользуемся `LabelEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>view_duration</th>\n",
       "      <th>view_ts</th>\n",
       "      <th>dt</th>\n",
       "      <th>platform</th>\n",
       "      <th>user_index</th>\n",
       "      <th>item_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4649</td>\n",
       "      <td>52867</td>\n",
       "      <td>735</td>\n",
       "      <td>2019-03-18 20:40:57+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>802</td>\n",
       "      <td>22812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>48800</td>\n",
       "      <td>361</td>\n",
       "      <td>2019-03-18 11:48:27+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>2</td>\n",
       "      <td>20399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5380</td>\n",
       "      <td>47146</td>\n",
       "      <td>268</td>\n",
       "      <td>2019-02-17 13:06:33+03:00</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>LG</td>\n",
       "      <td>911</td>\n",
       "      <td>19628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4498</td>\n",
       "      <td>30191</td>\n",
       "      <td>297</td>\n",
       "      <td>2019-03-18 15:27:18+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>773</td>\n",
       "      <td>13517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4886</td>\n",
       "      <td>39349</td>\n",
       "      <td>302</td>\n",
       "      <td>2019-03-18 12:08:16+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>836</td>\n",
       "      <td>16959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
       "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
       "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
       "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
       "3     4498       30191            297 2019-03-18 15:27:18+03:00 2019-03-18   \n",
       "4     4886       39349            302 2019-03-18 12:08:16+03:00 2019-03-18   \n",
       "\n",
       "  platform  user_index  item_index  \n",
       "0       LG         802       22812  \n",
       "1       LG           2       20399  \n",
       "2       LG         911       19628  \n",
       "3       LG         773       13517  \n",
       "4       LG         836       16959  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# кодируем индексы пользователей\n",
    "user_encoder = LabelEncoder()\n",
    "user_encoder.fit(content_views.user_id)\n",
    "\n",
    "# ереиндексация контента\n",
    "content_views = content_views.assign(\n",
    "    user_index = user_encoder.transform(content_views.user_id)\n",
    ")\n",
    "\n",
    "# кодируем индексы контента\n",
    "item_encoder = LabelEncoder()\n",
    "item_encoder.fit(content_views.content_id)\n",
    "\n",
    "# нова переиндексация\n",
    "content_views = content_views.assign(\n",
    "    item_index = item_encoder.transform(content_views.content_id)\n",
    ")\n",
    "\n",
    "\n",
    "content_views.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть колонки `user_index, item_index`, которые соответствуют номерам строки и столбца соответственно в матрице user-item. Передадим полученные колонки в конструктор `csr_matrix`, чтобы получить разреженную матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2000x27012 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 259994 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "num_users = content_views.user_index.max() + 1\n",
    "num_items = content_views.item_index.max() + 1\n",
    "num_interactions = content_views.shape[0]\n",
    "\n",
    "user_item = csr_matrix(\n",
    "    (np.ones(num_interactions),(content_views.user_index.values, content_views.item_index.values)),\n",
    "    shape=(num_users, num_items)\n",
    ")\n",
    "print('sparsity: %.4f' % (num_interactions / (num_users * num_items)))\n",
    "\n",
    "user_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем выборку на валидацию и контроль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Размер обучающей выборки 1600 пользователей\n",
      "        Размер валидационной выборки 400 пользователей\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ids, test_ids = train_test_split(\n",
    "    np.arange(start=0, stop=user_item.shape[0], step=1, dtype=np.uint32),\n",
    "    test_size=0.2\n",
    ")\n",
    "print(\n",
    "    \"\"\"\n",
    "        Размер обучающей выборки %d пользователей\n",
    "        Размер валидационной выборки %d пользователей\n",
    "    \"\"\"\n",
    "    % (train_ids.size, test_ids.size)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что в наше матрице 2000 пользователей и 27012 единиц контента, у матрицы высокая разреженность - менее 1% ненулевых элементов, остальное заполнено нулями.\n",
    "\n",
    "Чтобы строить рекомендации по колаборативной модели, нам нужен быстрый способ поиска пользователей, у которых схожая история просмотров- наше предположение в том, что похожие пользователи имеют похожую историю просмотров. Для поиска схожих пользователей воспользуемся поиском ближайших соседей по нашей матрице `user-item`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
       "                 metric_params=None, n_jobs=-1, n_neighbors=20, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "# обучаемся только на тренировочной части пользователей\n",
    "model_knn.fit(user_item[train_ids,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим простейший класс, который умеет искать похожих по истории смотрения пользователей и выдавать рекомендации. Рекомендации - это контент, который смотрели ближашие соседи пользователя, а сам пользователь этот контент не видел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColaborativeFilteringKNNRecommender:\n",
    "    def __init__(self, knn_model, user_item_matrix, num_neighbors):\n",
    "        self.knn_model = knn_model\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.top_recs = 50\n",
    "    \n",
    "    def make_recs(self, user_history: csr_matrix, top_recs: int):\n",
    "        neighbors = model_knn.kneighbors(\n",
    "            random_user_history,\n",
    "            self.num_neighbors,\n",
    "            return_distance=False\n",
    "        )[0]\n",
    "        full_recs = user_item[neighbors,:].max(axis=0)\n",
    "        # рекомендации - это то, что насмотрели ближайшие соседи\n",
    "        user_history_ids = user_history.nonzero()[1]\n",
    "        # последовательность id того контента, который смотрели ближайшие соседи\n",
    "        full_recs_ids = full_recs.nonzero()[1][:self.top_recs]\n",
    "        # исключаем из рекомендаций то, что уже было у упользователя в историии\n",
    "        success_recs = np.array([i for i in full_recs_ids if i in user_history_ids])\n",
    "        print(\"Число успешных рекомендаций %d из %d\" % (success_recs.size, top_recs))\n",
    "        \n",
    "        return np.array([i for i in full_recs_ids if i not in user_history_ids])[:10]\n",
    "\n",
    "\n",
    "# объект рекомендателя\n",
    "recommender = ColaborativeFilteringKNNRecommender(\n",
    "    knn_model=model_knn,\n",
    "    user_item_matrix=user_item,\n",
    "    num_neighbors=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем рекомендатель для случайного пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число успешных рекомендаций 6 из 10\n",
      "user_index 954, history: [   9   76  939  940  983 1086 1087 1088 1089 1090]\n",
      "recommendations: [ 687  988 1250 1254 1295 1300 1303 1307 1416 1500]\n"
     ]
    }
   ],
   "source": [
    "# пример рекомендаций для случайного пользователя\n",
    "random_user_index = np.random.choice(test_ids)\n",
    "random_user_history = user_item.getrow(random_user_index).reshape(1, -1)\n",
    "\n",
    "recs = recommender.make_recs(random_user_history, top_recs=10)\n",
    "print('user_index %d, history: %s' % (random_user_index, random_user_history.nonzero()[1][:10]))\n",
    "print('recommendations: %s' % recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашняя работа: строим KNN\n",
    "\n",
    "В реальной жизни KNN-рекомендатель не стоит делать на основе `sklearn.neighbors.NearestNeighbors` - есть готовые реализации, заточенные специально для построения рекомендательных систем. Хорошим примером такой реализации является [пакет implictit](). В рамках домашней работы предлагается разобраться с реализацией KNN-рекомендателя из этой библиотеки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почитайте документацию по модулю `implicit.nearest_neighbours.CosineRecommender`. Обучите KNN-рекомендатель и воспользуйтесь методом `recommend` для построения рекомендаций\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: Item to Item\n",
    "\n",
    "Решите задачу c2c рекомендаций - вызовите метод [similar_items](https://implicit.readthedocs.io/en/latest/models.html?highlight=similar_items#implicit.recommender_base.RecommenderBase.similar_items) для  *item_id=1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы обучили простейшую рекомендательную систему, основанную на колаборативной фильтрации и поиске ближайших соседей. В следующем уроке мы узнаем, как перейти от рекомендаций основанных на knn к более сложной концепции эмбеддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 3. Эмбеддинги пользователей и контента (скрытые факторы)\n",
    "\n",
    "Рекомендации, которые строятся на основе KNN, имеют следующий недостаток: фактическим мы запоминаем матрицу `user-item` на этапе тренировки модели - такие модели называются *memory-based*. Это привобдит к большому расходу памяти на этапе получения предсказаний, т.к. по каждому пользователю мы вынуждены хранить разреженный вектор большой размерности. При росте количества пользователей модель начинает критически быстро расти по памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой подход заключается в применении матричного разложения - когда мы пытаемся приблизить нашу большую разреженную матрицу user-item размерности $m\\times n$ двумя плотными матрицами, которые называются матрицей латентных (скрытых) факторов пользователей размерности $m\\times f$ и матрицей скрытых факторов контента размерности $n \\times f$. О таких методах мы уже говорили в уроке по теме \"Снижение размерности\" курса \"Машинное обучение. Начальный уровень\". Такой подход, при котором мы запоминаем не матрицу user-item, а только некий полезный сигнал из этой матрицы, называется *model-based*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фокус в том, что $m,n$ - это числа порядка десятков тысяч, а $f$ имеет небольшую размерность (обычно 30-50). Кажому пользователю и каждой единице понтента при таком подходе ставится в соответствие вектор размерности $f$, а произведение вектора пользователя $p_u$ на вектор контента $q_i$ даёт единственное число $r_{ui}$ - меру \"релевантности\", насколько данный контент понравится данному пользователю"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![svd_decomp](img/svd_decomp.png)\n",
    "\n",
    "$$\n",
    "r_{ui} = q_i^Tp_u\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для матричного разложения используются различные алгоритмы:\n",
    "\n",
    "* Singular Vector Decomposition (SVD)\n",
    "* Alternative Least Squares (ALS)\n",
    "* Bayesian personalized ranking (BPR)\n",
    "\n",
    "При решении реальных задач советую начать с BPR - он даёт отличные результаты, но у него есть и недостаток - вычислительная сложность, которая увеличивает время обучения.\n",
    "\n",
    "Выбирая между SVD и ALS я рекомендую выбирать ALS, т.к. он более новый и более быстрый."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы продемонстрируем работу рекомендательной системы на примере SVD-разложения - для этотго даже не нужно устанавливать дополнительные пакеты, нужная функция есть прямо в пакете `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 27012) (2000, 50) (27012, 50)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "latent_factors_num = 50\n",
    "# раскладываем Useк-Item матрицу\n",
    "user_factors, scale, item_factors = svds(\n",
    "    user_item.asfptype(),\n",
    "    k=latent_factors_num,\n",
    "    return_singular_vectors=True\n",
    ")\n",
    "scale = np.diag(np.sqrt(scale))\n",
    "# эмбеддинги пользователей\n",
    "user_factors = np.dot(user_factors, scale).astype(np.float32)\n",
    "# эмбеддинги контента\n",
    "item_factors = np.dot(scale, item_factors).astype(np.float32)\n",
    "\n",
    "print(user_item.shape, user_factors.shape, item_factors.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спроектируем класс, который будет формировать рекомендации на основе матриц `user_factors` и `item_factors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16421,  8459, 15912, 17787, 23459, 26717,  2484, 13301, 13309,\n",
       "       23456, 13344,   603])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ColaborativeFilteringFactorizationRecommender:\n",
    "    def __init__(self, user_factors, item_factors, user_item_matrix):\n",
    "        self.user_factors = user_factors\n",
    "        self.item_factors = item_factors\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "    \n",
    "    def make_recs(self, user_index):\n",
    "        user_factors = self.user_factors[user_index,:]\n",
    "        user_history_ids = self.user_item_matrix.getrow(user_index).nonzero()[1]\n",
    "        # рекомендации - это произведение вектора на матрицу\n",
    "        personal_scores = user_factors.reshape(1, -1).dot(self.item_factors).flatten()\n",
    "        personal_recs = np.argsort(-personal_scores)[:20]\n",
    "        \n",
    "        return np.array([i for i in personal_recs if i not in user_history_ids])\n",
    "\n",
    "factorization_recommender = ColaborativeFilteringFactorizationRecommender(\n",
    "    user_factors=user_factors,\n",
    "    item_factors=item_factors,\n",
    "    user_item_matrix=user_item\n",
    ")\n",
    "\n",
    "random_user_index = np.random.choice(test_ids)\n",
    "factorization_recommender.make_recs(random_user_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колаборативная модель на основе скрытых факторов пользователя/контента позволяет быстро получить список релевантного контента для каждого пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: обучаем Implicit\n",
    "\n",
    "Почитайте документацию по модулю implicit.als.AlternatingLeastSquares. Обучите ALS-рекомендатель и воспользуйтесь методом recommend для построения рекомендаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этому уроке мы поговорили о том, как перейти от memory-based рекомендателям к model-based. В следующем уроке обсудим, а как измеряют эффективность рекомендательных систем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики рекомендательных систем\n",
    "\n",
    "Мы научились делать персональные рекомендации единиц каталога. В этом уроке поговорим о том, как отделить \"хорошие\" модели от \"плохих\"\n",
    "\n",
    "Метрики рекомендательной системы (как и любых других продакшн-систем) можено разделить на три основных группы\n",
    "\n",
    "* оффлайн-метрики модели\n",
    "* продуктовые (бизнес) метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продуктовые метрики - это то, как пользователи реагируют на рекомендации. К пользовательским метрикам можно отнести:\n",
    "\n",
    "* конверсию (в просмотр, в покупку и т.д.) - чем выше конверсия, тем лучше модель \n",
    "* длительность нахождения на сервисе (чем дольше, тем лучше)\n",
    "* поизицию, до которой были просмотрены рекомендации - чем меньше позиций пролистали, тем лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Продуктовые метрики** (иногда их называют онлайн-метриками) можно измерить, только проведя АБ-тест, эксперимент на реальных пользователях сервиса. Механика проведения эксперимента следующая мы делим пользователей на две группы: группа А видит старый вариант алгоритма, группа Б - новый вариант. После окончания теста сравнивается значение в тестовой группе и контрольной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оффлайн-метрики** рекомендательных систем позволяют проверить, насколько качественные прогнозы выполняет модель, пользуясь историческими данными.\n",
    "\n",
    "Для этой задачи можно приспособить известную Вам метрику **RMSE**, которая определяет, насколько точно мы приблизили матрицу *user-item*\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(a_{ij}-\\hat{a}_{ij})^2}\n",
    "$$\n",
    "\n",
    "Где $a_{ij}$ - истинное значение фидбека пользователя $i$ для контента $j$, а $\\hat{a}_{ij}$ - значение фидбэка, которое предсказала наша модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это неплохая метрика, например, для задачи регрессии, но для рекомендаций она немного странная - в принципе, нам не важно, насколько хорошо предсказываются оценки 2,3,4 - мы хотим уверенном предсказывать высокие оценки: 8,9,10.\n",
    "\n",
    "Другой пример метрик - это метрики из задач классификации (precision + reccall).\n",
    "\n",
    "Допустим, у нас есть список рекомендаций из $n=5$ элементов и список фактических просмотров из $k=3$ элементов. В красную рамку обведены те рекомендации, которые были фактически просмотрены - количество таких фильмов $m = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eval](img/eval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall**  показывает отношение товаров, купленных из рекомендаций к общему числу фактических просмотров\n",
    "\n",
    "$$\n",
    "\\text{recall} = \\frac{m}{k} = \\frac{2}{3}\n",
    "$$\n",
    "\n",
    "**Precision**  показывает, насколько много из рекомендованного нами попало в итоге в просмотренное\n",
    "\n",
    "$$\n",
    "\\text{precision} = \\frac{m}{n} = \\frac{2}{5}\n",
    "$$\n",
    "\n",
    "У precision заметен один недостаток - игнорируется порядок, в котором пользователя заинтересовали рекомендованные объекты. Эту задачу решает метрика *average precision at K*. В числителе дисконтируем каждую \"единичку\", на ту позицию, где она стоит:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{ap} = \\frac{1}{5}\\left( 0 + \\frac{1}{2} + \\frac{1}{3}\\right) = \\frac{1}{5}\\cdot \\frac{5}{6} = \\frac{1}{6}\n",
    "$$\n",
    "\n",
    "при такой модификации мы заставляем модель не просто угадывать релевантные объекты, но и \"поднимать\" их выше к началу списка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме перечисленных выше метрик, которые измеряют точность \"угадывания\", можно мерять и другие показатели\n",
    "\n",
    "* diversity (разннообразие выдачи) - как сильно в выдаче представлены разные жанры, авторы и т.д.\n",
    "* coverage (покарытие каталога) - какая часть каталога покрывается рекомендациями (следует избегать случаев, когда всем пользователям рекомендуюется одно и то же подмножество)\n",
    "* serendipity (индивидуальность) -  берем разницу между вероятностью рекомендации айтема юзеру и всем юзерам (т.е. насколько рекомендация индивидуальна) и суммируем по всем релевантным рекомендованым айтемам. Позволяет определить, насколько выдача \"заточена\" под польователя\n",
    "* novelty (новизна) - как часто попадают в выдачу новые (холодные) элементы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание на метрики\n",
    "\n",
    "Даны два вектора - истинная история пользователя и объекты, которые считает релеватными ваша модель\n",
    "\n",
    "Вычислите\n",
    "\n",
    "* precision\n",
    "* recall\n",
    "* precision@5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "user_interactions = [47315, 30004, 36322,  8942, 30820,  6086,  9126,   332, 16289,\n",
    "       39106, 39335, 48506, 48654,  9234, 29935,  2678, 36202, 22636, 18007, 39328, 15414, 30016, 35601,\n",
    "    58409, 21313,   386, 16303, 4397, 19644, 51887, 21659, 36325, 53030,  7764, 50266, 58734, 53419, 24121,\n",
    "    50806, 36092,  8868, 28037, 36131, 13561, 16298, 27508, 41722, 30189, 46490,  2676, 43328, 781, 48397,\n",
    "    41369, 39324, 36381, 39635, 27710, 47837, 28525, 12024, 56604, 41664, 37387, 48507, 413, 33526, 20059,\n",
    "    49781, 56648, 16283, 50805, 34254, 39325, 59374, 22620,  8865, 27512, 13875, 30011,  7621,\n",
    "    10544, 28076, 29716, 30054, 20490, 29466, 16852, 39363, 34250, 7024, 33541,   263, 21267, 25690, 23020,\n",
    "    41368, 53414,  2681, 30201] \n",
    "\n",
    "user_recs = [\n",
    "    50820, 27781, 36131, 50812, 36092, 12024, 59155, 30042, 15414, 19882, 21659, 27849, 39328, 34240, 2681,\n",
    "    21267, 50126, 58560, 7764, 49781\n",
    "]\n",
    "\n",
    "# --- ВАШ КОД ТУТ ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке познакомились с метриками. Теперь вы можете отличать хорошие модели рекомендаций от плохих."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом модуле мы мознакомились с темой рекомендательных систем. Это область знаний, которую \"просто выучить, сложно понять\" - потому что с помощью простых алгоритмов ML можно сильно увеличить эффективность вашего бизнеса, но правильное применение этих методов к задаче построения рекомендательной системы - особое искусство, требующее хорошего понимания бизнес-области и знания специфических метрик систем ранжирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
