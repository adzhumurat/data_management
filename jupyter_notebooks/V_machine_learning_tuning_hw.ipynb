{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача на регуляризцию\n",
    "\n",
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество на валидации: 0.119\n",
      "Качество на обучении: 0.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/www/app/.venv/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.97797e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_degrees(source_data: list, degree: int):\n",
    "    \"\"\"Функция, которая принимает на вход одномерный массив, а возвращает n-мерный\n",
    "    Для каждой степени от 1 до  degree возводим x в эту степень\n",
    "    \"\"\"\n",
    "    return np.array([\n",
    "          source_data**n for n in range(1, degree + 1)  \n",
    "    ]).T\n",
    "\n",
    "data = pd.read_csv('data/non_linear.csv', sep=',')\n",
    "data.head()\n",
    "\n",
    "degree = 8\n",
    "X = generate_degrees(data['x_train'], degree)\n",
    "y = data.y_train.values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "model = Ridge(alpha=0).fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "y_pred_train = model.predict(X_train)\n",
    "print(\"Качество на валидации: %.3f\" % mean_squared_error(y_valid, y_pred))\n",
    "print(\"Качество на обучении: %.3f\" % mean_squared_error(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "у класса *Ridge* в конструкторе есть параметр регуляризации - обучите регрессию при $\\alpha=0.01$. \n",
    "\n",
    "Как изменилась ошибка на обучении? Как изменилась ошибка на валидации? Удалось ли победить переобучение? Используйте степень полинома n=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашняя работа: Lasso vs Ridge\n",
    "\n",
    "На данных из файла `data/non_linear.csv`\n",
    "* сгенерируйте данные до степени *degree = 8* включительно\n",
    "* обучите модель `sklearn.linear_model.Lasso` и модель `sklearn.linear_model.Ridge` на полученных данных\n",
    "* используйте коэффициент регуляризации $\\alpha=0.8$ для обеих моделей\n",
    "* постройте два столбчатых графика, на которых отобразите величину коэффициентов в для Ridge регрессии и Lasso регрессии виде столбиков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример графиков для 3-й степени (просто для примера, у вас может по-другому выглядеть). Какой можно сделать в вывод по величине коэффициентов?:\n",
    "![coeff_example](img/coeff_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ ---\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Домашнее задание: пишем Ridge регрессию.\n",
    "\n",
    "Мы использовали реализацию Ridge регрессию из библиотеки sklearn. Для того, чтобы  прокачать навыки программирования и освежить в памяти, как перемножать матрицы в numpy, напишите код для вычисления коэффициентов полиномиальной регрессии (для степени *degree=8*) с регуляризацией по формуле\n",
    "$$\n",
    "\\overline{w} = \\left(X^TX + \\lambda E\\right)^{-1}X^T\\overline{y}\n",
    "$$\n",
    "\n",
    "Для примера можно ориентироваться на то, как была реализована аналитическая формула для линейной регрессии в модуле \"Линейная регрессия. Часть I\"\n",
    "\n",
    "Единичную матрицу $E$ можно получить с помощью функции https://docs.scipy.org/doc/numpy/reference/generated/numpy.eye.html . Размерность матрицы $k\\times k$ (по количеству коэффициентов линейной регрессии). Напоминаю, что количество коэффициентов регрессии совпадает с количеством фичей регрессии, в задании будет $k=8$, т.к. генерим признаки для полинома восьмой степени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Домашнее задание: подбираем шаг градиентного спуска \n",
    "\n",
    "Очевидно, что чем больше шаг градиентного спуска (параметр *eta0* класса *SGDRegressor*), тем быстрее мы придём к оптимальным значениям. Используя под выше, поиграйтесь с параметром *eta0* и добейтесь , чтобы градиентный спуск закончился быстрее, чем за 200 шагов.\n",
    "\n",
    "Сколько шагов у вас получилось? Какое качество *RMSE* у Вашего решения? Визуализируйте функцию потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Домашнее задание: SGD на многомерных данных\n",
    "\n",
    "Примените градиентный спуск к задаче прогнозирования цен на недвижимость в Бостоне. Какого качества на валидации удалось достичь по r2-score? Сколько итераций  понадобилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston_dataset = load_boston()\n",
    "X = boston_dataset.data\n",
    "y = boston_dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Домашняя работа: добавляем регуляризацию в SGD\n",
    "\n",
    "В реализацию функции `gradient` добавьте параметр $\\lambda$, чтобы получить регуляризованный градиентный спуск\n",
    "\n",
    "Формула поменяется следующим образом:\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{cc}\n",
    "\\frac{\\partial L}{\\partial w_0} = \\frac{2}{n}\\cdot(-1)\\cdot \\sum_{i=1}^{n} 1\\cdot \\left(y_i - \\sum_{j=1}^{m}w_jx_j^i + 2\\cdot 1\\right)&\\\\\n",
    "\\frac{\\partial L}{\\partial w_k} = \\frac{2}{n}\\cdot(-1)\\cdot \\sum_{i=1}^{n} x_k^i \\cdot\\left(y_i - \\sum_{j=1}^{m}w_jx_j^i + 2x_k\\right)& k\\neq 0 \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "В этом модуле мы узнали, как  обучать линейную регрессию, не \"упираясь\" в аппаратные ресурсы: использовать градиентный спуск.\n",
    "Мы узнали, как детектировать переобучение модели и закрепили свои знания на примере полиномиальной регрессии и выяснили, как увеличить качество решения с помощью механизма регуляризации. Познакомились с двумя видами регуляризации -  Ridge и Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем исходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_train</th>\n",
       "      <th>y_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.182421</td>\n",
       "      <td>1.860341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.251605</td>\n",
       "      <td>1.878928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.270474</td>\n",
       "      <td>2.430015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.402553</td>\n",
       "      <td>2.327856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.427711</td>\n",
       "      <td>2.203649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x_train   y_train\n",
       "5  1.182421  1.860341\n",
       "6  1.251605  1.878928\n",
       "7  1.270474  2.430015\n",
       "8  1.402553  2.327856\n",
       "9  1.427711  2.203649"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/non_linear.csv', sep=',')\n",
    "data = data[(data.x_train > 1) & (data.x_train < 5)].copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код для SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def gradient(X, y, w, alpha=0) -> np.array:\n",
    "    # количество обучающих примеров в выборке\n",
    "    n = X.shape[0]\n",
    "    # считаем прогноз\n",
    "    y_hat = X.dot(w.T)\n",
    "    # вычисляем ошибку прогноза\n",
    "    error = y - y_hat\n",
    "    # дальше pointwise перемножение - умножаем каждую из координат на ошибку\n",
    "    pointwise_errors = np.multiply(X, error) + X\n",
    "    # print(pointwise_errors.shape, X.shape, error.shape)\n",
    "    grad = pointwise_errors.sum(axis=0)*(-1.0)*2.0 / n\n",
    "    return grad, error\n",
    "\n",
    "def eval_w_next(X, y, eta, w_current):\n",
    "    # вычисляем градиент\n",
    "    grad, error = gradient(X, y, w_current)\n",
    "    # делаем шаг градиентного спуска\n",
    "    w_next = w_current - eta*grad\n",
    "    # проверяем условие сходимости\n",
    "    weight_evolution = distance.euclidean(w_current, w_next)\n",
    "    return (w_next, weight_evolution, grad)\n",
    "\n",
    "def gradient_descent(X: np.array, y: np.array, eta=0.01, epsilon=0.001) -> np.array:\n",
    "    m = X.shape[1] # количество фичей\n",
    "    # инициализируем рандомом веса\n",
    "    w = np.random.random(m).reshape(1, -1)\n",
    "    w_next, weight_evolution, grad = eval_w_next(X, y, eta, w)\n",
    "    step = 0\n",
    "    # повторяем до сходимости вектора весов\n",
    "    while weight_evolution > epsilon:\n",
    "        w = w_next\n",
    "        w_next, weight_evolution, grad = eval_w_next(X, y, eta, w)\n",
    "        step += 1\n",
    "        if step % 100 ==0:\n",
    "            print(\"step %s |w-w_next|=%.5f, grad=%s\" % (step, weight_evolution, grad))\n",
    "    return w\n",
    "\n",
    "# трансформируем плоский массив X в вектор-столбец\n",
    "X = data['x_train'].values.reshape(-1, 1)\n",
    "n = X.shape[0]\n",
    "# добавляем тривиальный признак w_0, столбец из единиц. См. прошлый урок, почему так\n",
    "X = np.hstack([\n",
    "    np.ones(n).reshape(-1,1),\n",
    "    X\n",
    "])\n",
    "w = gradient_descent(X, data['y_train'].values.reshape(-1, 1), eta=0.008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание: извлечение признаков из текста\n",
    "\n",
    "Реализуем пайплайн в виде функции, при помощи которой обработаем все текстовые описания. Для каждого описания\n",
    "* проводим токенизацию\n",
    "* удаляем пунктуацию\n",
    "* приводим к нижнему регистру\n",
    "* удаляем стоп-слова\n",
    "\n",
    "\n",
    "Примените процедуру токенизации к файлу brand_tweets_valid.csv\n",
    "\n",
    "Сколько уникальных токенов получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    []\n",
       "1    []\n",
       "2    []\n",
       "3    []\n",
       "4    []\n",
       "Name: tokenized, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_text(raw_text: str):\n",
    "    \"\"\"Функция для токенизации текста\n",
    "    \n",
    "    :param raw_text: исходная текстовая строка\n",
    "    \"\"\"\n",
    "    filtered_tokens = []\n",
    "    # -- ВАШ КОД ТУТ --\n",
    "    \n",
    "    # -----------------\n",
    "    return filtered_tokens\n",
    "\n",
    "# применяем функцию в датафрейму с помощью метода .apply()\n",
    "tokenized_tweets= df.tweet_text.apply(tokenize_text)\n",
    "\n",
    "# добавляем новую колонку в исходный датафрейм\n",
    "df = df.assign(\n",
    "    tokenized=tokenized_tweets\n",
    ")\n",
    "\n",
    "df.tokenized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание: поиск дубликатов в тексте\n",
    "\n",
    "Потренируйтесь в нахождении матрицы схожести для валидационного сета\n",
    "\n",
    "загрузите brand_tweets_valid.csv\n",
    "примените объект vectorizer, обученный на датасете brand_tweets.csv (просто скопируйте этот код из урока)\n",
    "примените функцию pairwise_distances к полученной матрице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_valid = pd.read_csv('data/brand_tweets_valid.csv', sep=',', encoding='utf8')\n",
    "# удаляем строки, в которых отсутствует текст твита\n",
    "df_valid.drop(df_valid[df_valid.tweet_text.isnull()].index, inplace=True)\n",
    "\n",
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Пользуясь матрицей схожести, полученной на предыдущем этапе, найдите top-5 твитов, похожих на твит валидационного сета с id=14.\n",
    "\n",
    "У вас есть матрица схожести между объектами. Попробуйте решить задачу поиска дубликатов в тексте\n",
    "\n",
    "1. Визуализируйте гистограмму значений в матрице схожести\n",
    "1. Напишите функцию на Python, которая принимает индекс твита, пороговое значение (число от $0.0$ до $1.0$ и матрицу схожести, а затем выводит все твиты, схожесть которых больше, чем пороговое значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
